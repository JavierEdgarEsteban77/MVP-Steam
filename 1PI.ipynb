{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Logo.png\" alt=\"logo\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:blue\">\n",
    "Presentado por el Alumno: Javier Edgar Esteban \n",
    "Ghithub: JavierEdgarEsteban77 \n",
    "Carrera: DataScience Cohorte 05PT 02 Año 2.023</h5>\n",
    "\n",
    "<h3 style=\"color:green\">\n",
    "Proyecto: Obtención del Minimum Viable Product (MUV) solicitado por la empresa Steam sobre la recomendación de videos juegos y optimización para usuarios: 'worried'</h3>\n",
    "\n",
    "<h5 style=\"color:white\">\n",
    "Propuesta de Trabajo\n",
    "\n",
    "En este notebook primero vamos a trabajar el Extract, Transform and Load (ETL) el cual trabajaremos el Rol de Data Engineer y posteriormente el \n",
    "\n",
    "Análisis Exploratorio de Datos (EDA).\n",
    "\n",
    "La impronta que tendrá este trabajo individual desde el punto de vista técnico es extraer los datos en dónde trabajaremos los archivos:\n",
    "\n",
    "steam_games.json; user__reviews.json y users_items.json\n",
    "\n",
    "Cargo los datos de archivos JSON y los convierto en DataFrames de Pandas. Una vez transformados a nuestros df, estaremos en condición de la posterior preparación de la documentación para poder realizar un correcto análisis exploratorio que satisfaga las nececidades de nuestro cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías necesarias\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Creo la función para por leer las líneas de cada dataset\n",
    "def leer_datos(ruta, tipo='json'):\n",
    "    \"\"\"\n",
    "    Esta función lee datos desde cada archivo de mi carpeta y los convierte en un DataFrame de pandas.\n",
    "\n",
    "    Args:\n",
    "        ruta (str): La ruta al archivo que se va a leer.\n",
    "        tipo (str, optional): El formato de los datos en el archivo. Puede ser 'json' o 'literal'. \n",
    "                              Si es 'json', los datos se cargarán utilizando json.loads. \n",
    "                              Si es 'literal', los datos se cargarán utilizando ast.literal_eval. \n",
    "                              Por defecto es 'json'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un DataFrame de pandas que contiene los datos leídos del archivo.\n",
    "    \"\"\"\n",
    "    filas = []  # Lista para almacenar cada fila de datos\n",
    "\n",
    "    # Abre el archivo en modo lectura con codificación utf-8\n",
    "    with open(ruta, encoding='utf-8') as f:\n",
    "        # Lee cada línea del archivo\n",
    "        for line in tqdm(f.readlines(), desc=f\"Leyendo {ruta}\"):\n",
    "            # Si el tipo es 'json', carga los datos con json.loads\n",
    "            if tipo == 'json':\n",
    "                data = json.loads(line)\n",
    "            # Si el tipo es 'literal', carga los datos con ast.literal_eval\n",
    "            elif tipo == 'literal':\n",
    "                data = ast.literal_eval(line)\n",
    "            # Añade los datos a la lista de filas\n",
    "            filas.append(data)\n",
    "\n",
    "    # Convierte la lista de filas en un DataFrame de pandas y lo devuelve\n",
    "    return pd.DataFrame(filas)\n",
    "\n",
    "# Determino la ruta de cada dataset\n",
    "ruta_games = r'C:\\Users\\Esteban García\\OneDrive\\Escritorio\\LABs\\PIMLOPS JEE\\Borrador PI_ML_OPS\\Archivado Data\\steam_games.json'\n",
    "ruta_reviews = r'C:\\Users\\Esteban García\\OneDrive\\Escritorio\\LABs\\PIMLOPS JEE\\Borrador PI_ML_OPS\\Archivado Data\\user_reviews.json'\n",
    "ruta_items = r'C:\\Users\\Esteban García\\OneDrive\\Escritorio\\LABs\\PIMLOPS JEE\\Borrador PI_ML_OPS\\Archivado Data\\users_items.json'\n",
    "\n",
    "# Convierto en dataframe cada datasets\n",
    "df_steam_games = leer_datos(ruta_games, tipo='json')\n",
    "df_user_reviews = leer_datos(ruta_reviews, tipo='literal')\n",
    "df_users_items = leer_datos(ruta_items, tipo='literal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">\n",
    "Nuestros dataframes se llaman: df_steam_games; df_user_reviews y df_users_items\n",
    "\n",
    "<h5 style=\"color:blue\">\n",
    "Trabajaré son Steam Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizo el contenido para poder analizar los pasos a seguir.\n",
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El df_steam_games tiene {df_steam_games.shape[0]} filas y {df_steam_games.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizo la información contenida, normalizo mi df_steam_games eliminando filas vacías, NaN y analizaremos en porcentajes cuántos datos nulos o vacíos representan en el total del df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librería necesaria.\n",
    "import pandas as pd\n",
    "\n",
    "# Guardo el número de filas antes de la eliminación\n",
    "num_rows_before = df_steam_games.shape[0]\n",
    "\n",
    "# Imprimo los tipos de datos por columna y cantidad de nulos.\n",
    "print(df_steam_games.dtypes)\n",
    "print(df_steam_games.isnull().sum())\n",
    "\n",
    "# Elimino las filas vacías donde todos los valores son NaN\n",
    "df_steam_games = df_steam_games.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Reseteo el índice del DataFrame\n",
    "df_steam_games.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Guardo el número de filas después de la eliminación\n",
    "num_rows_after = df_steam_games.shape[0]\n",
    "\n",
    "# Calculo la reducción porcentual\n",
    "reduction_percentage = (1 - num_rows_after / num_rows_before) * 100\n",
    "\n",
    "# Imprimo la reducción porcentual\n",
    "print(f\"La reducción de filas es aproximadamente del {reduction_percentage:.2f}%.\")\n",
    "\n",
    "# Verifico los tipos de datos por columna.\n",
    "print(df_steam_games.dtypes)\n",
    "\n",
    "# Reviso las columnas\n",
    "for col in df_steam_games.columns:\n",
    "    print(f\"Columna: {col}\")\n",
    "    print(f\"Primer valor: {df_steam_games[col].iloc[0]}\")\n",
    "    \n",
    "    # Convierto las listas a cadenas antes de llamar a unique()\n",
    "    unique_values = pd.Series([str(x) if isinstance(x, list) else x for x in df_steam_games[col]]).unique()\n",
    "    print(f\"Valores únicos: {unique_values}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecciono los tipos de datos de cada columna en tu DataFrame\n",
    "print(df_steam_games.dtypes)\n",
    "\n",
    "# Si alguna columna es de tipo 'object', podría contener datos anidados\n",
    "object_cols = df_steam_games.select_dtypes(include=['object']).columns\n",
    "print('Columnas que podrían contener datos anidados:', object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" procederé a visualizar las columnas que contienen una lista o un diccionario \"\"\"\n",
    "\n",
    "# Importo lobrerías necesarias.\n",
    "import pandas as pd\n",
    "\n",
    "# Itero sobre cada columna\n",
    "for column in df_steam_games.columns:\n",
    "    # Obtiengo el primer valor no nulo\n",
    "    non_null_values = df_steam_games[column].dropna()\n",
    "    if non_null_values.empty:\n",
    "        print(f\"La columna '{column}' solo contiene valores nulos.\")\n",
    "        continue\n",
    "    first_non_null_value = non_null_values.iloc[0]\n",
    "\n",
    "    # Compruebo si es una lista o un diccionario\n",
    "    if isinstance(first_non_null_value, list):\n",
    "        print(f\"La columna '{column}' contiene una lista.\")\n",
    "    elif isinstance(first_non_null_value, dict):\n",
    "        print(f\"La columna '{column}' contiene un diccionario.\")\n",
    "    else:\n",
    "        print(f\"La columna '{column}' no contiene ni listas ni diccionarios.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" procederé a recontar valores únicos en orden descendente, \n",
    "por lo que el primer elemento es el elemento que ocurre con más frecuencia.\"\"\"\n",
    "\n",
    "# Calculo los recuentos de valores\n",
    "publisher_counts = df_steam_games['publisher'].value_counts()\n",
    "\n",
    "# Muestro los recuentos de valores en formato de tabla\n",
    "print(publisher_counts.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré genres, tags y specs las eliminaré.\n",
    "\n",
    "#### Vamos a realizar un preprocesamiento y análisis, aplanado listas, tratando valores nulos y creando variables ficticias cuya finalidad es transformar datos categóricos en un formato numérico para que los algoritmos de machine learning puedan procesar más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso el método explode en múltiples columnas.\n",
    "df_steam_games = df_steam_games.explode('genres').explode('tags').explode('specs')\n",
    "\n",
    "# Elimino valores NaN\n",
    "df_steam_games = df_steam_games.dropna(subset=['genres', 'tags', 'specs'])\n",
    "\n",
    "# Especifico el número de filas a mostrar\n",
    "df_steam_games[['genres', 'tags', 'specs']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games = df_steam_games.drop(['tags', 'specs'], axis=1)\n",
    "df_steam_games.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero un gráfico para representar la frecuencia de cada género."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo librerías.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Contar la frecuencia de cada género\n",
    "genre_counts = df_steam_games['genres'].value_counts()\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(genre_counts.index, genre_counts.values, color='b')\n",
    "\n",
    "plt.xlabel('Géneros')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Frecuencia de los géneros en los juegos de Steam')\n",
    "plt.xticks(rotation=90)  # Rotar las etiquetas del eje x para una mejor visualización\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veo anomalías en los nombres, procederemos a renombrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazo caracteres especiales HTML en valores para mejorar la legibilidad.\n",
    "df_steam_games['genres'] = df_steam_games['genres'].str.replace('&', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico las filas duplicadas\n",
    "duplicados = df_steam_games[df_steam_games.duplicated(subset='id', keep=False)]\n",
    "print(duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino los duplicados de la columna 'genres'\n",
    "df_steam_games = df_steam_games.drop_duplicates(subset=['id', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_steam_games['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazo los NaN por 'Sin Dato'\n",
    "df_steam_games['genres'] = df_steam_games['genres'].fillna('Sin Dato')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_steam_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré app_name y title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro filas sin nulos en app_name o title.\n",
    "df_steam_games = df_steam_games[(df_steam_games.app_name.notna()) & (df_steam_games.title.notna())] \n",
    "\n",
    "# Hago una mascara cuando app_name sea diferente a title.\n",
    "diferentes = (df_steam_games[\"app_name\"] != df_steam_games[\"title\"])\n",
    "\n",
    "# Obtengo los indices True de diferentes.\n",
    "indices_true = diferentes.index[diferentes]\n",
    "\n",
    "# Visualizo algunos resultados después de aplicar los filtros.\n",
    "df_steam_games.loc[indices_true, [\"app_name\", \"title\"]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica si 'app_name' y 'title' son iguales para todas las filas\n",
    "son_iguales = (df_steam_games['app_name'] == df_steam_games['title']).all()\n",
    "\n",
    "print(f\"¿Son 'app_name' y 'title' iguales para todas las filas? {son_iguales}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizo ¿cuántos juegos únicos por categoría hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_games_per_genre = df_steam_games.groupby('genres')['id'].nunique()\n",
    "print(unique_games_per_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creare un gráfico para ver el top ten de los juegos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias.\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asumiendo que 'df_steam_games' es tu DataFrame y 'genres' es tu columna\n",
    "top_ten_genres = df_steam_games['genres'].value_counts().nlargest(10)\n",
    "\n",
    "print(\"Top 10 géneros de juegos más representados:\\n\", top_ten_genres)\n",
    "\n",
    "# Crear la nube de palabras\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top_ten_genres)\n",
    "\n",
    "# Mostrar la nube de palabras\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaré un modelo de clasificación basado en categorías para comprender un poco más la información de genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificar los géneros como números\n",
    "le = LabelEncoder()\n",
    "genres_encoded = le.fit_transform(df_steam_games['genres'])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas que necesitas\n",
    "df_model = df_steam_games[['id']].copy()\n",
    "df_model['genres_encoded'] = genres_encoded\n",
    "\n",
    "# Usar la columna 'id' como característica, omitiendo las filas con valores NaN\n",
    "df_model_no_nan = df_model.dropna(subset=['id'])\n",
    "X = df_model_no_nan[['id']]  \n",
    "y = df_model_no_nan['genres_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tengo mi modelo lo entrenaré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré reviews_url si no lo considero necesario, la eliminaré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games['reviews_url'].head().to_frame().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías.\n",
    "# pip install pandas\n",
    "\n",
    "# Elimino la columna reviews_url\n",
    "# df_steam_games = df_steam_games.drop(columns=['reviews_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré release_date.\n",
    "\n",
    "Luego de haber realizado las correcciones pertinentes y su limpieza, puedo afirmar que no tenemos datos nulos; a continuación procedo a la conversión de la columna 'release_date' a datetime y la renombre año de lanzamiento y creo la columna 'año'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierto la columna release_date a datetime\n",
    "df_steam_games['release_date'] = pd.to_datetime(df_steam_games['release_date'], errors='coerce')\n",
    "\n",
    "# Renombro la columna release_date a 'año de lanzamiento'\n",
    "df_steam_games.rename(columns={'release_date': 'año de lanzamiento'}, inplace=True)\n",
    "\n",
    "# Creo la columna 'año'\n",
    "df_steam_games['año'] = df_steam_games['año de lanzamiento'].dt.year\n",
    "\n",
    "# Analizo los datos\n",
    "print(df_steam_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la popularidad de los juegos por año de lanzamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la librería necesaria\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creo una serie con la cantidad de videojuegos según su año de lanzamiento.\n",
    "games_by_year = df_steam_games.groupby(\"año\").size()\n",
    "\n",
    "# Hago un gráfico de barras de games_by_year.\n",
    "plt.bar(games_by_year.index, games_by_year.values)\n",
    "\n",
    "# Ajusto opciones del gráfico.\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Cantidad de videojuegos\")\n",
    "plt.title(\"Cantidad de videojuegos según su año de lanzamiento\")\n",
    "plt.xlim(1970, 2025)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la biblioteca necesaria.\n",
    "import pandas as pd\n",
    "\n",
    "# Defino una función para reemplazar las cadenas de texto a 0.0\n",
    "def replace_price(price):\n",
    "    if isinstance(price, str):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return price\n",
    "\n",
    "# Corrijo precios en df_steam_games\n",
    "df_steam_games['price'].replace({'Starting at $499.00': 499.0, 'Starting at $449.00': 499.0}, inplace=True)\n",
    "\n",
    "# Aplico la función a la columna price\n",
    "df_steam_games['price'] = df_steam_games['price'].apply(replace_price)\n",
    "\n",
    "# Calculo la cantidad de valores nulos en cada columna\n",
    "nulos = df_steam_games.isnull().sum()\n",
    "\n",
    "# Calculo el porcentaje de filas con valores nulos en las columnas 'developer' y 'año de lanzamiento'\n",
    "porcentaje_nulos = 1 - df_steam_games.dropna(subset=[\"developer\",\"año de lanzamiento\"]).shape[0] / df_steam_games.shape[0]\n",
    "\n",
    "print(df_steam_games.head())\n",
    "print(df_steam_games['price'].head())\n",
    "print(df_steam_games['price'].tail())\n",
    "print(df_steam_games['price'].describe())\n",
    "print(df_steam_games['price'].value_counts())\n",
    "print(nulos)\n",
    "print(f'Porcentaje de nulos : {porcentaje_nulos}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré early_acces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cuento la cantidad de juegos en 'Early Access' y no en 'Early Access'\n",
    "early_access_counts = df_steam_games['early_access'].value_counts()\n",
    "\n",
    "# Creo un gráfico de pastel\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(early_access_counts, labels=['No Early Access', 'Early Access'], autopct='%1.1f%%',\n",
    "        colors=['skyblue', 'yellowgreen'])\n",
    "plt.title('Proporción de juegos en Early Access vs No Early Access')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizo el número de nulos en la columna 'id'\n",
    "print(\"El número de nulos en la columna 'id' es:\", df_steam_games.id.isna().sum())\n",
    "\n",
    "# Elimino las filas con valores NaN\n",
    "df_steam_games.dropna(inplace=True)\n",
    "\n",
    "# Imprimo el número de duplicados en la columna 'id'\n",
    "print(\"El número de duplicados en la columna 'id' es:\", df_steam_games.id.duplicated().sum())\n",
    "\n",
    "# Elimino los duplicados en la columna 'id'\n",
    "df_steam_games.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "\n",
    "# Reseteo el índice del DataFrame\n",
    "df_steam_games.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Imprimo el número de registros y el número de 'id' únicos\n",
    "print(f\"El número de registros es {df_steam_games.shape[0]}.\")\n",
    "print(f\"El número de 'id' únicos es {df_steam_games.id.nunique()}.\")\n",
    "\n",
    "# Convierto 'id' a número para ahorrar espacio de almacenamiento\n",
    "df_steam_games[\"id\"] = df_steam_games[\"id\"].astype(\"int32\")\n",
    "\n",
    "# Cambio el nombre de la columna 'id' a 'user_id'\n",
    "df_steam_games.rename(columns={'id': 'user_id'}, inplace=True)\n",
    "\n",
    "# Verifico los cambios\n",
    "print(df_steam_games.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaré developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cuento la cantidad de juegos por desarrollador\n",
    "developer_counts = df_steam_games['developer'].value_counts()\n",
    "\n",
    "# Imprimo los primeros 10 desarrolladores con más juegos\n",
    "print(\"Top 10 desarrolladores con más juegos:\\n\", developer_counts.head(10))\n",
    "\n",
    "# Creo un gráfico de barras con los primeros 10 desarrolladores con más juegos\n",
    "developer_counts.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 desarrolladores con más juegos')\n",
    "plt.xlabel('Desarrollador')\n",
    "plt.ylabel('Cantidad de juegos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">\n",
    "Ahora bien analizamos los títulos de los juegos de Steam mediante el uso de técnicas de procesamiento del lenguaje natural en dónde encontraremos tendencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_steam_game_titles(df_steam_games):\n",
    "  \"\"\"\n",
    "  Analizo los títulos de los juegos de Steam.\n",
    "\n",
    "  Args:\n",
    "    df_steam_games: Un DataFrame de pandas con los juegos de Steam.\n",
    "\n",
    "  Returns:\n",
    "    Una lista con los títulos completos.\n",
    "  \"\"\"\n",
    "\n",
    "  # Accedo a la columna de los títulos del DataFrame\n",
    "  titles = df_steam_games[\"title\"].tolist()\n",
    "\n",
    "  return titles  # Devuelve una lista con los títulos completos\n",
    "\n",
    "# Analizo los títulos de los juegos\n",
    "titles = analyze_steam_game_titles(df_steam_games)\n",
    "\n",
    "# Creo una nube de palabras con los títulos completos\n",
    "wordcloud = WordCloud(width=800, height=600, background_color=\"white\").generate(' '.join(titles))\n",
    "\n",
    "# Muestro la nube de palabras\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue\">\n",
    "Ahora trabajaré con User Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya realizada la carga anteiormente, vemos su contenido\n",
    "df_user_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_user_reviews.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecciono los tipos de datos de cada columna en tu DataFrame\n",
    "print(df_user_reviews.dtypes)\n",
    "\n",
    "# Si alguna columna es de tipo 'object', podría contener datos anidados\n",
    "object_cols = df_user_reviews.select_dtypes(include=['object']).columns\n",
    "print('Columnas que podrían contener datos anidados:', object_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observo que en la columna 'reviews' contiene un diccionario, lo voy a desanidar para agregar a mi actual df las nuevas columnas fruto del desanidado y consecuentemente procederé a realizar un análisis de experiencia de usuario por Análisis de Sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra el DataFrame para mostrar solo las filas duplicadas\n",
    "duplicated_rows = df_user_reviews[df_user_reviews.duplicated('user_id')]\n",
    "\n",
    "# Imprime las filas duplicadas\n",
    "print(duplicated_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procederé a eliminar los usuarios revisando si los reviews dentro de los datos anidados de 'reviews' la información se encuentra duplicada o si solo se duplica el 'user_id' porque hay más de un comentario realizado por ese usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Creo una nueva columna 'review_str' que convierte las reseñas en cadenas\n",
    "df_user_reviews['review_str'] = df_user_reviews['reviews'].apply(lambda x: str(x))\n",
    "\n",
    "# Obtengo los 'user_id' duplicados\n",
    "duplicated_user_ids = df_user_reviews[df_user_reviews.duplicated('user_id', keep=False)]['user_id'].unique()\n",
    "\n",
    "# Creo un nuevo DataFrame para almacenar las reseñas sin duplicados\n",
    "df_user_reviews_clean = df_user_reviews.copy()\n",
    "\n",
    "# Itero sobre los 'user_id' duplicados\n",
    "for user_id in tqdm(duplicated_user_ids):\n",
    "    # Encuentro las reseñas duplicadas para el 'user_id' actual\n",
    "    duplicate_reviews = df_user_reviews_clean[(df_user_reviews_clean['user_id'] == user_id) & df_user_reviews_clean.duplicated('review_str', keep=False)]\n",
    "\n",
    "# Si hay reseñas duplicadas, las elimino del DataFrame\n",
    "if not duplicate_reviews.empty:\n",
    "    df_user_reviews_clean.drop(duplicate_reviews.index, inplace=True)\n",
    "\n",
    "# Verifico si quedan duplicados\n",
    "remaining_duplicates = df_user_reviews_clean[df_user_reviews_clean.duplicated(['user_id', 'review_str'], keep=False)]\n",
    "if remaining_duplicates.empty:\n",
    "    print(\"No quedan reseñas duplicadas.\")\n",
    "else:\n",
    "    print(\"Aún quedan algunas reseñas duplicadas.\")\n",
    "\n",
    "# Elimino la columna 'review_str'\n",
    "df_user_reviews_clean.drop(columns='review_str', inplace=True)\n",
    "\n",
    "# Imprimo las columnas del DataFrame\n",
    "print(df_user_reviews_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_user_reviews.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la librería necesaria para realizar un desanidado.\n",
    "import pandas as pd\n",
    "\n",
    "# Desanido la columna 'reviews' y reemplazo los valores vacíos con 'Sin Dato'\n",
    "df_u_r_desanidado = pd.json_normalize(df_user_reviews['reviews'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else {'funny': 'Sin Dato', 'posted': 'Sin Dato', 'last_edited': 'Sin Dato', 'item_id': 'Sin Dato', 'helpful': 'Sin Dato', 'recommend': 'Sin Dato', 'review': 'Sin Dato'})).replace('', 'Sin Dato')\n",
    "\n",
    "# Concateno el DataFrame original con el DataFrame desanidado\n",
    "df_user_reviews_desanidado = pd.concat([df_user_reviews, df_u_r_desanidado], axis=1)\n",
    "\n",
    "# Muestra las primeras 5 filas de cada columna\n",
    "print(df_user_reviews_desanidado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una función para convertir los valores a enteros si es posible\n",
    "def to_int(x):\n",
    "    \"\"\"Intento convertir un valor dado a un entero. Si no es posible, retorna el valor original.\n",
    "\n",
    "    Args:\n",
    "        x (Any): El valor a convertir.\n",
    "\n",
    "    Returns:\n",
    "        Union[int, Any]: Retorna el valor convertido a int si es posible, de lo contrario retorna el valor original.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(x)\n",
    "    except ValueError:\n",
    "        return x\n",
    "# Aplico la función a la columna 'user_id'\n",
    "df_user_reviews_desanidado['user_id'] = df_user_reviews_desanidado['user_id'].apply(to_int)\n",
    "# Veo ¿cómo quedaron las columnas de mi df?\n",
    "print(df_user_reviews_desanidado.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias y descargo el léxico de VADER\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "# Creo el analizador de sentimientos\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Defino la función para clasificar los sentimientos\n",
    "def classify_sentiment(text):\n",
    "    \"\"\"Clasifica el sentimiento de un texto dado utilizando la puntuación de polaridad.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto a clasificar.\n",
    "\n",
    "    Returns:\n",
    "        int: Retorna 2 si el texto es positivo, 0 si es negativo, y 1 si es neutral o 'Sin Dato'.\n",
    "    \"\"\"\n",
    "    if text == 'Sin Dato':\n",
    "        return 1  # Neutral\n",
    "    sentiment_score = sia.polarity_scores(text)\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 2  # Positivo\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 0  # Negativo\n",
    "    else:\n",
    "        return 1  # Neutral\n",
    "\n",
    "# Aplico la función a la columna de reseñas y elimino la columna 'review'\n",
    "tqdm.pandas()\n",
    "df_user_reviews_desanidado['sentiment_analysis'] = df_user_reviews_desanidado['review'].progress_apply(classify_sentiment)\n",
    "df_user_reviews_desanidado.drop(columns=['review'], inplace=True)\n",
    "\n",
    "# Muestra las primeras 5 filas de cada columna\n",
    "print(df_user_reviews_desanidado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo el número total de reseñas\n",
    "total_reviews = df_user_reviews_desanidado.shape[0]\n",
    "# Calculo el número de reseñas en cada categoría de sentimiento\n",
    "positive_reviews = df_user_reviews_desanidado[df_user_reviews_desanidado['sentiment_analysis'] == 2].shape[0]\n",
    "neutral_reviews = df_user_reviews_desanidado[df_user_reviews_desanidado['sentiment_analysis'] == 1].shape[0]\n",
    "negative_reviews = df_user_reviews_desanidado[df_user_reviews_desanidado['sentiment_analysis'] == 0].shape[0]\n",
    "# Calculo los porcentajes\n",
    "positive_percentage = (positive_reviews / total_reviews) * 100\n",
    "neutral_percentage = (neutral_reviews / total_reviews) * 100\n",
    "negative_percentage = (negative_reviews / total_reviews) * 100\n",
    "\n",
    "print(f\"Porcentaje de reseñas positivas: {positive_percentage}%\")\n",
    "print(f\"Porcentaje de reseñas neutrales: {neutral_percentage}%\")\n",
    "print(f\"Porcentaje de reseñas negativas: {negative_percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">\n",
    "Conclusión: la mayoría de las reseñas de los juegos son positivas en un 63.84%, mientras que un 21.28% son neutrales y un 14.88% son negativas. Podríamos trabajar en la mejora de experiencia de usuario para mejorar los valores neutrales y cambiar radicalmente el porcentaje de las experiencias negativas, realizando un análisis más profundo en cada caso en particular. Esto proporciona una visión general de las opiniones de los usuarios sobre los juegos y lo que tendríamos que trabajar para mejorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizo los outliers ya que veo que tenemos outliers\n",
    "Q1 = df_user_reviews_desanidado['sentiment_analysis'].quantile(0.25)\n",
    "Q3 = df_user_reviews_desanidado['sentiment_analysis'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df_user_reviews_desanidado[(df_user_reviews_desanidado['sentiment_analysis'] < Q1 - 1.5 * IQR) | (df_user_reviews_desanidado['sentiment_analysis'] > Q3 + 1.5 * IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizo los outliers ya que veo que tenemos outliers\n",
    "Q1 = df_user_reviews_desanidado['sentiment_analysis'].quantile(0.25)\n",
    "Q3 = df_user_reviews_desanidado['sentiment_analysis'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df_user_reviews_desanidado[(df_user_reviews_desanidado['sentiment_analysis'] < Q1 - 1.5 * IQR) | (df_user_reviews_desanidado['sentiment_analysis'] > Q3 + 1.5 * IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizo una visualización de los datos para una mejor comprensión final\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_user_reviews_desanidado['sentiment_analysis'], bins=3, alpha=0.5)\n",
    "plt.xlabel('Análisis de Sentimientos')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.title('Histograma de Análisis de Sentimiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:gray\">\n",
    "“El histograma muestra la distribución de los resultados de nuestro análisis de sentimientos. La barra de la izquierda representa las reseñas con sentimiento negativo, la barra del medio representa las reseñas con sentimiento neutral, y la barra de la derecha representa las reseñas con sentimiento positivo. La altura de cada barra indica la cantidad de reseñas que caen en cada categoría de sentimiento.”\n",
    "\n",
    "<h3 style=\"color:blue\">\n",
    "Ahora trabajaré el Users Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya realizada la carga anteiormente, vemos su contenido\n",
    "df_users_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observo que en la columna 'items' contiene un diccionario, lo voy a desanidar para agregar a mi actual df las nuevas columnas fruto del desanidado y consecuentemente procederé a realizar una normalización de los datos para trabajar en ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la librerías necesarias\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "# Desanido la columna 'items'\n",
    "df_u_i_desanidado = pd.json_normalize(df_users_items['items'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else {'item_id': 'Sin Dato', 'item_name': 'Sin Dato'}))\n",
    "# Reemplazo los valores vacíos con 'Sin Dato'\n",
    "df_u_i_desanidado = df_u_i_desanidado.replace('', 'Sin Dato')\n",
    "# Elimino la columna 'items' del DataFrame original\n",
    "df_users_items = df_users_items.drop(columns=['items'])\n",
    "# Concateno el DataFrame original con el DataFrame desanidado\n",
    "df_users_items_desanidado = pd.concat([df_users_items, df_u_i_desanidado], axis=1)\n",
    "# Imprimo las primeras 5 filas del DataFrame\n",
    "print(df_users_items_desanidado.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lo que haré a continuación, es un análisis de tiempo de juego y detección de Outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías necesarias\n",
    "import pandas as pd\n",
    "\n",
    "# Verifico los valores nulos y los tipos de datos\n",
    "print(df_users_items_desanidado.isnull().sum())\n",
    "print(df_users_items_desanidado[['playtime_forever', 'playtime_2weeks']].dtypes)\n",
    "\n",
    "# Lleno los valores nulos con 0\n",
    "df_users_items_desanidado[['playtime_forever', 'playtime_2weeks']] = df_users_items_desanidado[['playtime_forever', 'playtime_2weeks']].fillna(0)\n",
    "\n",
    "# Creo una función para detectar outliers\n",
    "def detect_outliers(df, column):\n",
    "    \"\"\"Detecta los valores atípicos en una columna específica de un DataFrame utilizando el método del rango intercuartil (IQR).\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): El DataFrame en el que se buscarán los valores atípicos.\n",
    "        column (str): El nombre de la columna en la que se buscarán los valores atípicos.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Un DataFrame que contiene solo las filas del DataFrame original que tienen valores atípicos en la columna especificada.\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = df[(df[column] < Q1 - 1.5 * IQR) | (df[column] > Q3 + 1.5 * IQR)]\n",
    "    return outliers\n",
    "\n",
    "# Detecto los outliers para 'playtime_forever' y 'playtime_2weeks'\n",
    "outliers_forever = detect_outliers(df_users_items_desanidado, 'playtime_forever')\n",
    "outliers_2weeks = detect_outliers(df_users_items_desanidado, 'playtime_2weeks')\n",
    "\n",
    "# Muestro un resumen estadístico de la actividad del jugador y los outliers detectados\n",
    "print(df_users_items_desanidado.describe())\n",
    "print(outliers_forever)\n",
    "print(outliers_2weeks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voy a proceder a visualizar en gráficos subplots para comparar los resultados de ambos y manejo de outliers en Tiempos de Juego de Usuarios de Steam y manejo de outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Defino el plot\n",
    "def plot_histogram(ax, data, title, xlabel, ylabel):\n",
    "    ax.hist(data, bins=10, alpha=0.5)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_violinplot(ax, data, labels, ylabel, title):\n",
    "    sns.violinplot(ax=ax, data=data)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Defino los outliers\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    P95 = df[column].quantile(0.95)\n",
    "    df.loc[df[column] > Q3 + 1.5 * IQR, column] = P95\n",
    "\n",
    "# Creo una figura y tres ejes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Creo los histogramas y el gráfico de violín\n",
    "plot_histogram(axs[0], df_users_items_desanidado['playtime_forever'], 'Histograma de Tiempo de Juego Total', 'Tiempo de Juego Total', 'Cantidad de Usuarios')\n",
    "plot_histogram(axs[1], df_users_items_desanidado['playtime_2weeks'], 'Histograma de Tiempo de Juego en las Últimas 2 Semanas', 'Tiempo de Juego en las Últimas 2 Semanas', 'Cantidad de Usuarios')\n",
    "plot_violinplot(axs[2], df_users_items_desanidado[['playtime_forever', 'playtime_2weeks']], ['Tiempo de Juego Total', 'Tiempo de Juego en las Últimas 2 Semanas'], 'Cantidad de Usuarios', 'Gráfico de Violín del Tiempo de Juego')\n",
    "\n",
    "# Muestro los gráficos\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Manejo los outliers para 'playtime_forever' y 'playtime_2weeks'\n",
    "handle_outliers(df_users_items_desanidado, 'playtime_forever')\n",
    "handle_outliers(df_users_items_desanidado, 'playtime_2weeks')\n",
    "\n",
    "# Lleno los valores nulos con 0\n",
    "df_users_items_desanidado['playtime_forever'].fillna(0, inplace=True)\n",
    "df_users_items_desanidado['playtime_2weeks'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:gray\">\n",
    "Los tres gráficos proporcionan una visión detallada de los patrones de juego de los usuarios. El primer gráfico, un histograma del tiempo total de juego, muestra que la mayoría de los usuarios han jugado menos de 50,000 minutos en total, indicando que la mayoría de los usuarios son jugadores ocasionales. Sin embargo, hay algunos usuarios que han jugado mucho más, lo que indica la presencia de jugadores más dedicados.\n",
    "\n",
    "El segundo gráfico es un histograma del tiempo de juego en las últimas 2 semanas. Este gráfico muestra una mayor variabilidad en el tiempo de juego, lo que podría indicar que los patrones de juego de los usuarios cambian con el tiempo, posiblemente debido a factores como el lanzamiento de nuevos juegos, actualizaciones de juegos existentes, o cambios en el tiempo libre de los usuarios.\n",
    "\n",
    "El tercer gráfico es un boxplot que compara la distribución del tiempo total de juego y el tiempo de juego en las últimas 2 semanas. Este gráfico destaca la existencia de outliers, que son usuarios que han jugado significativamente más que otros. Estos outliers podrían ser jugadores extremadamente dedicados o podrían indicar comportamientos de juego anómalos que podrían ser de interés para futuras investigaciones.\n",
    "\n",
    "En conjunto, estos gráficos ofrecen una visión detallada de cómo los usuarios interactúan con los juegos a lo largo del tiempo, lo que podría ser útil para entender mejor los comportamientos de los jugadores y para informar decisiones sobre el diseño de juegos y la orientación de marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procederé a guardar en formato csv cada df que he trabajado ya que no observo datos atípicos ni anomalías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la librería que necesito\n",
    "import os\n",
    "\n",
    "# Diccionario de tus DataFrames y los nombres deseados para los archivos CSV\n",
    "dataframes = {\n",
    "    'df_steam_games': 'steam_games',\n",
    "    'df_user_reviews_desanidado': 'user_reviews',\n",
    "    'df_users_items_desanidado': 'users_items'\n",
    "}\n",
    "\n",
    "# Ruta base donde se guardarán los archivos CSV\n",
    "ruta_base = r'Data'\n",
    "\n",
    "for df_nombre, csv_nombre in dataframes.items():\n",
    "    # Crear la ruta completa del archivo CSV\n",
    "    ruta_archivo_csv = os.path.join(ruta_base, f'{csv_nombre}.csv')   \n",
    "    # Guardar el DataFrame como archivo CSV\n",
    "    globals()[df_nombre].to_csv(ruta_archivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías necesarias\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cargo los DataFrames\n",
    "df_steam_games = pd.read_csv(r'Data\\steam_games.csv')\n",
    "df_user_reviews_desanidado = pd.read_csv(r'Data\\user_reviews.csv')\n",
    "df_users_items_desanidado = pd.read_csv(r'Data\\users_items.csv')\n",
    "\n",
    "# Tomo una muestra de 100 datos de cada DataFrame\n",
    "df_steam_games_sample = df_steam_games.sample(100)\n",
    "df_user_reviews_desanidado_sample = df_user_reviews_desanidado.sample(100)\n",
    "df_users_items_desanidado_sample = df_users_items_desanidado.sample(100)\n",
    "\n",
    "def PlayTimeGenre(genero: str):\n",
    "    # Filtro df_steam_games_sample por género\n",
    "    games_of_genre = df_steam_games_sample[df_steam_games_sample[genero] == 1]['app_name']\n",
    "    \n",
    "    # Filtro df_users_items_desanidado_sample por juegos del género especificado\n",
    "    playtime_of_genre = df_users_items_desanidado_sample[df_users_items_desanidado_sample['item_name'].isin(games_of_genre)]\n",
    "    \n",
    "    # Agrupo por año y sumar playtime_forever\n",
    "    playtime_by_year = playtime_of_genre.groupby('anio')['playtime_forever'].sum()\n",
    "    \n",
    "    # Encuentro el año con más horas jugadas\n",
    "    year_with_most_playtime = playtime_by_year.idxmax()\n",
    "    \n",
    "    return {\"Año de lanzamiento con más horas jugadas para \" + genero : year_with_most_playtime}\n",
    "\n",
    "def UserForGenre(genero: str):\n",
    "    # Filtro df_steam_games_sample por género\n",
    "    games_of_genre = df_steam_games_sample[df_steam_games_sample[genero] == 1]['app_name']\n",
    "    \n",
    "    # Filtro df_users_items_desanidado_sample por juegos del género especificado\n",
    "    playtime_of_genre = df_users_items_desanidado_sample[df_users_items_desanidado_sample['item_name'].isin(games_of_genre)]\n",
    "    \n",
    "    # Agrupo por usuario y sumar playtime_forever\n",
    "    playtime_by_user = playtime_of_genre.groupby('user_id')['playtime_forever'].sum()\n",
    "    \n",
    "    # Encuentro el usuario con más horas jugadas\n",
    "    user_with_most_playtime = playtime_by_user.idxmax()\n",
    "    \n",
    "    # Agrupo por año y sumar playtime_forever\n",
    "    playtime_by_year = playtime_of_genre.groupby('anio')['playtime_forever'].sum().reset_index()\n",
    "    \n",
    "    # Convierto el DataFrame a una lista de diccionarios\n",
    "    playtime_list = playtime_by_year.to_dict('records')\n",
    "    \n",
    "    return {\"Usuario con más horas jugadas para \" + genero : user_with_most_playtime, \"Horas jugadas\": playtime_list}\n",
    "\n",
    "def UsersRecommend(año: int):\n",
    "    # Filtro df_user_reviews_desanidado_sample por año y recomendación\n",
    "    recommended_games = df_user_reviews_desanidado_sample[(df_user_reviews_desanidado_sample['posted'] == año) & (df_user_reviews_desanidado_sample['recommend'] == True)]\n",
    "    \n",
    "    # Cuento las recomendaciones por juego\n",
    "    recommendations_by_game = recommended_games['item_id'].value_counts()\n",
    "    \n",
    "    # Obtengo el top 3 de juegos más recomendados\n",
    "    top_3_games = recommendations_by_game.nlargest(3).index.tolist()\n",
    "    \n",
    "    return [{\"Puesto 1\" : top_3_games[0]}, {\"Puesto 2\" : top_3_games[1]}, {\"Puesto 3\" : top_3_games[2]}]\n",
    "\n",
    "def UsersNotRecommend(año: int):\n",
    "    # Filtro df_user_reviews_desanidado_sample por año y no recomendación\n",
    "    not_recommended_games = df_user_reviews_desanidado_sample[(df_user_reviews_desanidado_sample['posted'] == año) & (df_user_reviews_desanidado_sample['recommend'] == False)]\n",
    "    \n",
    "    # Cuento las no recomendaciones por juego\n",
    "    not_recommendations_by_game = not_recommended_games['item_id'].value_counts()\n",
    "    \n",
    "    # Obtengo el top 3 de juegos menos recomendados\n",
    "    top_3_games = not_recommendations_by_game.nlargest(3).index.tolist()\n",
    "    \n",
    "    return [{\"Puesto 1\" : top_3_games[0]}, {\"Puesto 2\" : top_3_games[1]}, {\"Puesto 3\" : top_3_games[2]}]\n",
    "\n",
    "def sentiment_analysis(año: int):\n",
    "    # Filtro df_user_reviews_desanidado_sample por año\n",
    "    reviews_of_year = df_user_reviews_desanidado_sample[df_user_reviews_desanidado_sample['posted'] == año]\n",
    "    \n",
    "    # Cuento las reseñas para análisis de sentimiento\n",
    "    sentiment_counts = reviews_of_year['sentiment_analysis'].value_counts().to_dict()\n",
    "    \n",
    "    return sentiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_steam_games.columns)\n",
    "print(df_user_reviews_desanidado.columns)\n",
    "print(df_users_items_desanidado.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Logo.png\" alt=\"logo\"\n",
    "<h1><strong><center> Proyecto Individual MLOps N° 1 Año 2.023<center></strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:blue\">\n",
    "Presentado por el Alumno: Javier Edgar Esteban \n",
    "Ghithub: JavierEdgarEsteban77 \n",
    "Carrera: DataScience Cohorte 05PT 02 Año 2.023</h5>\n",
    "\n",
    "<h3 style=\"color:green\">\n",
    "Proyecto: Obtención del Minimum Viable Product (MUV) solicitado por la empresa Steam sobre la recomendación de videos juegos y optimización para usuarios: 'worried'</h3>\n",
    "\n",
    "<h5 style=\"color:white\">\n",
    "Propuesta de Trabajo\n",
    "\n",
    "En este notebook primero vamos a trabajar el Extract, Transform and Load (ETL) el cual trabajaremos el Rol de Data Engineer y posteriormente el \n",
    "\n",
    "Análisis Exploratorio de Datos (EDA).\n",
    "\n",
    "La impronta que tendrá este trabajo individual desde el punto de vista técnico es extraer los datos en dónde trabajaremos los archivos:\n",
    "\n",
    "steam_games.json; user__reviews.json y users_items.json\n",
    "\n",
    "Cargo los datos de archivos JSON y los convierto en DataFrames de Pandas. Una vez transformados a nuestros df, estaremos en condición de la posterior preparación de la documentación para poder realizar un correcto análisis exploratorio que satisfaga las nececidades de nuestro cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías necesarias\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Creo la función para por leer las líneas de cada dataset\n",
    "def leer_datos(ruta, tipo='json'):\n",
    "    \"\"\"\n",
    "    Esta función lee datos desde cada archivo de mi carpeta y los convierte en un DataFrame de pandas.\n",
    "\n",
    "    Args:\n",
    "        ruta (str): La ruta al archivo que se va a leer.\n",
    "        tipo (str, optional): El formato de los datos en el archivo. Puede ser 'json' o 'literal'. \n",
    "                              Si es 'json', los datos se cargarán utilizando json.loads. \n",
    "                              Si es 'literal', los datos se cargarán utilizando ast.literal_eval. \n",
    "                              Por defecto es 'json'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un DataFrame de pandas que contiene los datos leídos del archivo.\n",
    "    \"\"\"\n",
    "    filas = []  # Lista para almacenar cada fila de datos\n",
    "\n",
    "    # Abre el archivo en modo lectura con codificación utf-8\n",
    "    with open(ruta, encoding='utf-8') as f:\n",
    "        # Lee cada línea del archivo\n",
    "        for line in tqdm(f.readlines(), desc=f\"Leyendo {ruta}\"):\n",
    "            # Si el tipo es 'json', carga los datos con json.loads\n",
    "            if tipo == 'json':\n",
    "                data = json.loads(line)\n",
    "            # Si el tipo es 'literal', carga los datos con ast.literal_eval\n",
    "            elif tipo == 'literal':\n",
    "                data = ast.literal_eval(line)\n",
    "            # Añade los datos a la lista de filas\n",
    "            filas.append(data)\n",
    "\n",
    "    # Convierte la lista de filas en un DataFrame de pandas y lo devuelve\n",
    "    return pd.DataFrame(filas)\n",
    "\n",
    "# Determino la ruta de cada dataset\n",
    "ruta_games = r'C:\\Users\\Esteban García\\OneDrive\\Escritorio\\LABs\\PIMLOPS JEE\\Borrador PI_ML_OPS\\Archivado Data\\steam_games.json'\n",
    "ruta_reviews = r'C:\\Users\\Esteban García\\OneDrive\\Escritorio\\LABs\\PIMLOPS JEE\\Borrador PI_ML_OPS\\Archivado Data\\user_reviews.json'\n",
    "ruta_items = r'C:\\Users\\Esteban García\\OneDrive\\Escritorio\\LABs\\PIMLOPS JEE\\Borrador PI_ML_OPS\\Archivado Data\\users_items.json'\n",
    "\n",
    "# Convierto en dataframe cada datasets\n",
    "df_steam_games = leer_datos(ruta_games, tipo='json')\n",
    "df_user_reviews = leer_datos(ruta_reviews, tipo='literal')\n",
    "df_users_items = leer_datos(ruta_items, tipo='literal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">\n",
    "Ahora tengo nuestros dataframes que se llaman: df_steam_games; df_user_reviews y df_users_items\n",
    "\n",
    "<h5 style=\"color:blue\">\n",
    "Trabajaré son Steam Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizo el contenido para poder analizar los pasos a seguir.\n",
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El df tiene {df_steam_games.shape[0]} filas y {df_steam_games.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizo la información contenida, normalizo mi df_steam_games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librería necesaria.\n",
    "import pandas as pd\n",
    "\n",
    "# Guarda el número de filas antes de la eliminación\n",
    "num_rows_before = df_steam_games.shape[0]\n",
    "\n",
    "# Elimino las filas vacías\n",
    "df_steam_games.dropna(how='all', inplace=True)\n",
    "\n",
    "# Guarda el número de filas después de la eliminación\n",
    "num_rows_after = df_steam_games.shape[0]\n",
    "\n",
    "# Calcula la reducción porcentual\n",
    "reduction_percentage = (1 - num_rows_after / num_rows_before) * 100\n",
    "\n",
    "# Imprime la reducción porcentual\n",
    "print(f\"La reducción de filas es aproximadamente del {reduction_percentage:.2f}%.\")\n",
    "\n",
    "# Verifico los tipos de datos por columna.\n",
    "print(df_steam_games.dtypes)\n",
    "\n",
    "# Reviso las columnas\n",
    "for col in df_steam_games.columns:\n",
    "    print(f\"Columna: {col}\")\n",
    "    print(f\"Primer valor: {df_steam_games[col].iloc[0]}\")\n",
    "    \n",
    "    # Convierto las listas a tuplas antes de llamar a unique()\n",
    "    unique_values = pd.Series([tuple(x) if isinstance(x, list) else x for x in df_steam_games[col]]).unique()\n",
    "    print(f\"Valores únicos: {unique_values}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuo con mi normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias\n",
    "import pandas as pd\n",
    "\n",
    "# Elimino las filas con valores NaN\n",
    "df_steam_games = df_steam_games.dropna()\n",
    "\n",
    "# Completo las URLs incompletas con 'Sin Dato'\n",
    "df_steam_games['url'] = df_steam_games['url'].apply(lambda x: x if x != '' else 'Sin Dato')\n",
    "\n",
    "# Convierto los valores 'Free To Play' en la columna 'price' a 0\n",
    "df_steam_games['price'] = df_steam_games['price'].apply(lambda x: 0 if x == 'Free To Play' else x)\n",
    "\n",
    "# Cambio el nombre de la columna 'id' a 'user_id'\n",
    "df_steam_games = df_steam_games.rename(columns={'id': 'user_id'})\n",
    "\n",
    "# Verifico los cambios\n",
    "print(df_steam_games.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observo que cuento con dos filas con Id nulo, la primera, tiene todos datos nulos, excepto la columna url y price, en cambio el segundo Id tiene datos nulos en la columna reviews_url e id y está replicada, veremos el procedimiento para limpiar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico las filas duplicadas\n",
    "duplicados = df_steam_games[df_steam_games.duplicated(subset='user_id', keep=False)]\n",
    "print(duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico 'user_id' \n",
    "df_steam_games.user_id.isna().sum()\n",
    "df_steam_games[df_steam_games.user_id.isna()]\n",
    "print(df_steam_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la biblioteca necesaria.\n",
    "import pandas as pd\n",
    "\n",
    "# Elimino las filas donde el título es 'Batman: Arkham City - Game of the Year Edition'.\n",
    "df_steam_games = df_steam_games[df_steam_games['title'] != 'Batman: Arkham City - Game of the Year Edition']\n",
    "\n",
    "# Elimino todos los duplicados.\n",
    "df_steam_games.drop_duplicates(subset='user_id', inplace=True, keep='first')\n",
    "\n",
    "# Verifico si todos los valores en la columna 'user_id' son enteros.\n",
    "es_entero = df_steam_games['user_id'].apply(lambda x: isinstance(x, int)).all()\n",
    "print(f\"Todos los valores son enteros: {es_entero}\")\n",
    "\n",
    "# Verifico si todos los valores en la columna 'user_id' son cadenas de caracteres.\n",
    "es_cadena = df_steam_games['user_id'].apply(lambda x: isinstance(x, str)).all()\n",
    "print(f\"Todos los valores son cadenas de caracteres: {es_cadena}\")\n",
    "\n",
    "# Elimino las filas con valores no numéricos en 'user_id'.\n",
    "df_steam_games = df_steam_games[df_steam_games['user_id'].apply(lambda x: str(x).isdigit())]\n",
    "\n",
    "# Paso el id a entero.\n",
    "df_steam_games['user_id'] = df_steam_games['user_id'].astype('int')\n",
    "\n",
    "# Chequeo las columnas.\n",
    "print(df_steam_games.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico si hay duplicados después de la eliminación.\n",
    "duplicados = df_steam_games[df_steam_games.duplicated(subset='user_id', keep=False)]\n",
    "print(\"Número de filas duplicadas después de la eliminación:\", len(duplicados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la biblioteca necesaria\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Verifico si las columnas existen en los DataFrames.\n",
    "if 'genres' in df_steam_games.columns and 'tags' in df_steam_games.columns:\n",
    "    # Identificar las filas con valores faltantes en 'genres' y 'tags'\n",
    "    missing_genres_steam = df_steam_games['genres'].isna()\n",
    "    missing_tags_games = df_steam_games['tags'].isna()\n",
    "\n",
    "    # Relleno los valores faltantes con la moda.\n",
    "    df_steam_games.loc[missing_genres_steam, 'genres'] = df_steam_games['genres'].mode()[0]\n",
    "    df_steam_games.loc[missing_tags_games, 'tags'] = df_steam_games['tags'].mode()[0]\n",
    "else:\n",
    "    print(\"Verifica los nombres de las columnas. No se encontraron 'genres' en df_steam_games o 'tags' en df_steam_games.\")\n",
    "    print(\"Columnas en df_steam_games: \", df_steam_games.columns)\n",
    "\n",
    "# Creo un conjunto de géneros de juegos\n",
    "genres = set(item for val in tqdm(df_steam_games['genres'].dropna(), desc=\"Creando conjunto de géneros\") for item in val)\n",
    "\n",
    "# Filtro las etiquetas 'tags' para mantener solo aquellas que están presentes en 'genres'\n",
    "df_steam_games['tags'] = df_steam_games['tags'].apply(lambda x: [item for item in x if item in genres] if isinstance(x, list) else x) \n",
    "\n",
    "# Relleno valores nulos en la columna 'genres' con valores correspondientes de 'tags'\n",
    "df_steam_games['genres'].fillna(df_steam_games['tags'], inplace=True)\n",
    "\n",
    "# Añado una función de valores de 'tags' a 'genres' que no estén ya presentes en 'genres'\n",
    "def agregar_genres_tags(fila): \n",
    "    \"\"\"\n",
    "    Agrega los elementos de 'tags' a 'genres' si no están ya presentes.\n",
    "\n",
    "    Args:\n",
    "        fila (dict): Un diccionario que contiene al menos las claves 'genres' y 'tags'. \n",
    "                     Ambos, 'genres' y 'tags', deben ser listas.\n",
    "\n",
    "    Returns:\n",
    "        list: La lista 'genres' actualizada con los elementos de 'tags' que no estaban presentes.\n",
    "    \"\"\"\n",
    "    genres = fila['genres']\n",
    "    tags = fila['tags']\n",
    "    if isinstance(tags,list) and isinstance(genres,list):\n",
    "        for tag in tags:\n",
    "            if tag not in genres:\n",
    "                genres.append(tag)\n",
    "    return genres\n",
    "\n",
    "# Aplico la función 'agregar_genres_tags' a todos los elementos en el dataframe\n",
    "df_steam_games['genres'] = df_steam_games.apply(lambda fila: agregar_genres_tags(fila), axis=1)\n",
    "\n",
    "# Genero dummies para genres con la finalidad de generar variables ficticias para géneros de juegos\n",
    "df_steam_games['genres'] = df_steam_games['genres'].apply(lambda x:\".\".join(x) if isinstance(x, list) else x)\n",
    "dummies = df_steam_games['genres'].str.get_dummies(sep='.')\n",
    "df_steam_games = pd.concat([df_steam_games,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a verificar como van quedando nuestros datos\n",
    "print(f\"El df tiene {df_steam_games.shape[0]} filas y {df_steam_games.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En esta otra etapa de mi ETL, voy a trabajar sobre las columnas de precios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la biblioteca necesaria\n",
    "import pandas as pd\n",
    "\n",
    "# Defino una función para reemplazar las cadenas de texto a 0.0\n",
    "def replace_price(price):\n",
    "    if isinstance(price, str):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return price\n",
    "\n",
    "# Corrijo precios en steam_proc\n",
    "df_steam_games['price'].replace({'Starting at $499.00': 499.0, 'Starting at $449.00': 499.0}, inplace=True)\n",
    "\n",
    "# Aplico la función a la columna price\n",
    "df_steam_games['price'] = df_steam_games['price'].apply(replace_price)\n",
    "\n",
    "# Calculo la cantidad de valores nulos en cada columna\n",
    "nulos = df_steam_games.isnull().sum()\n",
    "\n",
    "# Calculo el porcentaje de filas con valores nulos en las columnas 'developer' y 'release_date'\n",
    "porcentaje_nulos = 1 - df_steam_games.dropna(subset=[\"developer\",\"release_date\"]).shape[0] / df_steam_games.shape[0]\n",
    "\n",
    "print(df_steam_games.head())\n",
    "print(df_steam_games['price'].head())\n",
    "print(df_steam_games['price'].tail())\n",
    "print(df_steam_games['price'].describe())\n",
    "print(df_steam_games['price'].value_counts())\n",
    "print(nulos)\n",
    "print(f'Porcentaje de nulos : {porcentaje_nulos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luego de haber realizado las correcciones pertinentes y su limpieza, puedo afirmar que no tenemos datos nulos; a continuación procedo a la conversión de la columna 'release_date' a datetime y creación de la columna 'anio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la librería necesaria\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Defino una función para verificar si el año es válido\n",
    "def es_ano_valido(anio):\n",
    "    \"\"\"\n",
    "    Esta función verifica si el valor ingresado es un año válido.\n",
    "\n",
    "    Args:\n",
    "        anio (int): El año que se va a verificar.\n",
    "\n",
    "    Returns:\n",
    "        bool: Retorna True si el año es válido, False en caso contrario.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        datetime.datetime.strptime(str(anio), '%Y')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Convierto la columna release_date a datetime\n",
    "df_steam_games['release_date'] = pd.to_datetime(df_steam_games['release_date'], errors='coerce')\n",
    "\n",
    "# Genero la columna año\n",
    "df_steam_games['anio'] = df_steam_games['release_date'].dt.year\n",
    "\n",
    "# Verifico si el año es válido\n",
    "df_steam_games['es_ano_valido'] = df_steam_games['anio'].apply(es_ano_valido)\n",
    "\n",
    "# Analizo los datos\n",
    "print(df_steam_games)\n",
    "print(df_steam_games['es_ano_valido'])\n",
    "\n",
    "# Cuento la cantidad de veces que cada año aparece en la columna 'anio'\n",
    "value_counts = df_steam_games['anio'].value_counts()\n",
    "\n",
    "# Imprimo los años que sólo aparecen una vez\n",
    "print(value_counts[value_counts == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la popularidad de los juegos por año de lanzamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la biblioteca necesaria\n",
    "import pandas as pd\n",
    "\n",
    "# Creo una nueva columna 'anio_lanzamiento' que contiene el año de lanzamiento de cada juego\n",
    "df_steam_games['anio_lanzamiento'] = df_steam_games['release_date'].dt.year\n",
    "\n",
    "# Creo una nueva columna 'num_reviews' que contiene el número de reseñas de cada juego\n",
    "df_steam_games['num_reviews'] = df_steam_games['reviews_url'].apply(lambda x: len(x))\n",
    "\n",
    "# Obtengo los 10 juegos más populares de cada año\n",
    "top_juegos_por_anio = df_steam_games.groupby('anio_lanzamiento').apply(lambda x: x.nlargest(10, 'num_reviews'))\n",
    "\n",
    "# Muestro el DataFrame\n",
    "print(top_juegos_por_anio[['app_name', 'anio_lanzamiento', 'num_reviews']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuando con nuestra verificación de que los datos contenidos en la columna anio_lanzamiento, sea efectivamente años, y no tengamos años nulos, como así también que se lanzaron los juegos mostrando como salida el top ten por año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico\n",
    "df_steam_games['anio_lanzamiento'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo una máscara para comparar las columnas app_name y title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_steam_games.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro filas sin nulos en app_name o title.\n",
    "df_steam_games = df_steam_games[(df_steam_games.app_name.notna()) & (df_steam_games.title.notna())] \n",
    "\n",
    "# Hago una mascara cuando app_name sea diferente a title.\n",
    "diferentes = (df_steam_games[\"app_name\"] != df_steam_games[\"title\"])\n",
    "\n",
    "# Obtengo los indices True de diferentes.\n",
    "indices_true = diferentes.index[diferentes]\n",
    "\n",
    "# Visualizo algunos resultados después de aplicar los filtros.\n",
    "df_steam_games.loc[indices_true, [\"app_name\", \"title\"]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizando los datos provistos por la máscara, procedo a eliminar la columna 'title'\n",
    "df_steam_games.drop(\"title\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A continuación, procederé a analizar la columna 'app_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentro duplicados en app_name.\n",
    "duplicados_app_name = df_steam_games.app_name.duplicated().sum()\n",
    "\n",
    "# Imprimo la cantidad de duplicados.\n",
    "print(f\"Hay {duplicados_app_name} duplicados en app_name.\")\n",
    "\n",
    "# Si hay duplicados, guardarlos en una variable e imprimirlos.\n",
    "if duplicados_app_name > 0:\n",
    "    duplicados = df_steam_games[df_steam_games['app_name'].duplicated(keep=False)].sort_values(by=\"app_name\")\n",
    "    print(duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedo a eliminar los dupplicados.\n",
    "df_steam_games = df_steam_games.drop_duplicates(subset='app_name', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">\n",
    "Ahora bien analizamos los títulos de los juegos de Steam mediante el uso de técnicas de procesamiento del lenguaje natural en dónde encontraremos tendencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_steam_game_titles(df_steam_games):\n",
    "  \"\"\"\n",
    "  Analizo los títulos de los juegos de Steam.\n",
    "\n",
    "  Args:\n",
    "    df_steam_games: Un DataFrame de pandas con los juegos de Steam.\n",
    "\n",
    "  Returns:\n",
    "    Una lista con los títulos completos.\n",
    "  \"\"\"\n",
    "\n",
    "  # Accedo a la columna de los títulos del DataFrame\n",
    "  titles = df_steam_games[\"title\"].tolist()\n",
    "\n",
    "  return titles  # Devuelve una lista con los títulos completos\n",
    "\n",
    "# Analizo los títulos de los juegos\n",
    "titles = analyze_steam_game_titles(df_steam_games)\n",
    "\n",
    "# Creo una nube de palabras con los títulos completos\n",
    "wordcloud = WordCloud(width=800, height=600, background_color=\"white\").generate(' '.join(titles))\n",
    "\n",
    "# Muestro la nube de palabras\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_steam_game_genres_and_tags(df_steam_games):\n",
    "  \"\"\"\n",
    "  Analizo los géneros y las etiquetas de los juegos de Steam.\n",
    "\n",
    "  Args:\n",
    "    df_steam_games: Un DataFrame de pandas con los juegos de Steam.\n",
    "\n",
    "  Returns:\n",
    "    Una lista con los géneros y las etiquetas.\n",
    "  \"\"\"\n",
    "\n",
    "  # Accedo a las columnas de los géneros y las etiquetas del DataFrame\n",
    "  genres = df_steam_games[\"genres\"].apply(lambda x: ' '.join(x) if isinstance(x, list) else x).tolist()\n",
    "  tags = df_steam_games[\"tags\"].apply(lambda x: ' '.join(x) if isinstance(x, list) else x).tolist()\n",
    "\n",
    "  # Combino las listas de géneros y etiquetas\n",
    "  genres_tags = genres + tags\n",
    "\n",
    "  return genres_tags  # Devuelve una lista con los géneros y las etiquetas\n",
    "genres_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">\n",
    "Conclusión: podemos observar que los productos más consumidos son el género aventura y héroes y RPG en dónde los jugadores asumen el rol de un personaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue\">\n",
    "Ahora trabajaré con User Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya realizada la carga anteiormente, vemos su contenido\n",
    "df_user_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observo que en la columna 'reviews' contiene un diccionario, lo voy a desanidar para agregar a mi actual df las nuevas columnas fruto del desanidado y consecuentemente procederé a realizar un análisis de experiencia de usuario por Análisis de Sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la librería necesaria para realizar un desanidado.\n",
    "import pandas as pd\n",
    "\n",
    "# Desanido la columna 'reviews' y reemplazo los valores vacíos con 'Sin Dato'\n",
    "df_u_r_desanidado = pd.json_normalize(df_user_reviews['reviews'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else {'funny': 'Sin Dato', 'posted': 'Sin Dato', 'last_edited': 'Sin Dato', 'item_id': 'Sin Dato', 'helpful': 'Sin Dato', 'recommend': 'Sin Dato', 'review': 'Sin Dato'})).replace('', 'Sin Dato')\n",
    "\n",
    "# Concateno el DataFrame original con el DataFrame desanidado\n",
    "df_user_reviews_desanidado = pd.concat([df_user_reviews, df_u_r_desanidado], axis=1)\n",
    "\n",
    "# Muestra las primeras 5 filas de cada columna\n",
    "print(df_user_reviews_desanidado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una función para convertir los valores a enteros si es posible\n",
    "def to_int(x):\n",
    "    \"\"\"Intento convertir un valor dado a un entero. Si no es posible, retorna el valor original.\n",
    "\n",
    "    Args:\n",
    "        x (Any): El valor a convertir.\n",
    "\n",
    "    Returns:\n",
    "        Union[int, Any]: Retorna el valor convertido a int si es posible, de lo contrario retorna el valor original.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(x)\n",
    "    except ValueError:\n",
    "        return x\n",
    "# Aplico la función a la columna 'user_id'\n",
    "df_user_reviews_desanidado['user_id'] = df_user_reviews_desanidado['user_id'].apply(to_int)\n",
    "# Veo ¿cómo quedaron las columnas de mi df?\n",
    "print(df_user_reviews_desanidado.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procederé a calcular la experiencia de usuario y el porcentaje de las reseñas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias y descargo el léxico de VADER\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "# Creo el analizador de sentimientos\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Defino la función para clasificar los sentimientos\n",
    "def classify_sentiment(text):\n",
    "    \"\"\"Clasifica el sentimiento de un texto dado utilizando la puntuación de polaridad.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto a clasificar.\n",
    "\n",
    "    Returns:\n",
    "        int: Retorna 2 si el texto es positivo, 0 si es negativo, y 1 si es neutral o 'Sin Dato'.\n",
    "    \"\"\"\n",
    "    if text == 'Sin Dato':\n",
    "        return 1  # Neutral\n",
    "    sentiment_score = sia.polarity_scores(text)\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 2  # Positivo\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 0  # Negativo\n",
    "    else:\n",
    "        return 1  # Neutral\n",
    "\n",
    "# Aplico la función a la columna de reseñas y elimino la columna 'review'\n",
    "tqdm.pandas()\n",
    "df_user_reviews_desanidado['sentiment_analysis'] = df_user_reviews_desanidado['review'].progress_apply(classify_sentiment)\n",
    "df_user_reviews_desanidado.drop(columns=['review'], inplace=True)\n",
    "\n",
    "# Muestra las primeras 5 filas de cada columna\n",
    "print(df_user_reviews_desanidado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo el número total de reseñas\n",
    "total_reviews = df_user_reviews_desanidado.shape[0]\n",
    "# Calculo el número de reseñas en cada categoría de sentimiento\n",
    "positive_reviews = df_user_reviews_desanidado[df_user_reviews_desanidado['sentiment_analysis'] == 2].shape[0]\n",
    "neutral_reviews = df_user_reviews_desanidado[df_user_reviews_desanidado['sentiment_analysis'] == 1].shape[0]\n",
    "negative_reviews = df_user_reviews_desanidado[df_user_reviews_desanidado['sentiment_analysis'] == 0].shape[0]\n",
    "# Calculo los porcentajes\n",
    "positive_percentage = (positive_reviews / total_reviews) * 100\n",
    "neutral_percentage = (neutral_reviews / total_reviews) * 100\n",
    "negative_percentage = (negative_reviews / total_reviews) * 100\n",
    "\n",
    "print(f\"Porcentaje de reseñas positivas: {positive_percentage}%\")\n",
    "print(f\"Porcentaje de reseñas neutrales: {neutral_percentage}%\")\n",
    "print(f\"Porcentaje de reseñas negativas: {negative_percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">\n",
    "Conclusión: la mayoría de las reseñas de los juegos son positivas en un 63.84%, mientras que un 21.28% son neutrales y un 14.88% son negativas. Podríamos trabajar en la mejora de experiencia de usuario para mejorar los valores neutrales y cambiar radicalmente el porcentaje de las experiencias negativas, realizando un análisis más profundo en cada caso en particular. Esto proporciona una visión general de las opiniones de los usuarios sobre los juegos y lo que tendríamos que trabajar para mejorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizo los outliers ya que veo que tenemos outliers\n",
    "Q1 = df_user_reviews_desanidado['sentiment_analysis'].quantile(0.25)\n",
    "Q3 = df_user_reviews_desanidado['sentiment_analysis'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df_user_reviews_desanidado[(df_user_reviews_desanidado['sentiment_analysis'] < Q1 - 1.5 * IQR) | (df_user_reviews_desanidado['sentiment_analysis'] > Q3 + 1.5 * IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizo una visualización de los datos para una mejor comprensión final\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_user_reviews_desanidado['sentiment_analysis'], bins=3, alpha=0.5)\n",
    "plt.xlabel('Análisis de Sentimientos')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.title('Histograma de Análisis de Sentimiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:gray\">\n",
    "“El histograma muestra la distribución de los resultados de nuestro análisis de sentimientos. La barra de la izquierda representa las reseñas con sentimiento negativo, la barra del medio representa las reseñas con sentimiento neutral, y la barra de la derecha representa las reseñas con sentimiento positivo. La altura de cada barra indica la cantidad de reseñas que caen en cada categoría de sentimiento.”\n",
    "\n",
    "<h3 style=\"color:blue\">\n",
    "Ahora trabajaré el Users Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya realizada la carga anteiormente, vemos su contenido\n",
    "df_users_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observo que en la columna 'items' contiene un diccionario, lo voy a desanidar para agregar a mi actual df las nuevas columnas fruto del desanidado y consecuentemente procederé a realizar una normalización de los datos para trabajar en ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la librerías necesarias\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "# Desanido la columna 'items'\n",
    "df_u_i_desanidado = pd.json_normalize(df_users_items['items'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else {'item_id': 'Sin Dato', 'item_name': 'Sin Dato'}))\n",
    "# Reemplazo los valores vacíos con 'Sin Dato'\n",
    "df_u_i_desanidado = df_u_i_desanidado.replace('', 'Sin Dato')\n",
    "# Elimino la columna 'items' del DataFrame original\n",
    "df_users_items = df_users_items.drop(columns=['items'])\n",
    "# Concateno el DataFrame original con el DataFrame desanidado\n",
    "df_users_items_desanidado = pd.concat([df_users_items, df_u_i_desanidado], axis=1)\n",
    "# Imprimo las primeras 5 filas del DataFrame\n",
    "print(df_users_items_desanidado.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lo que haré a continuación, es un análisis de tiempo de juego y detección de Outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías necesarias\n",
    "import pandas as pd\n",
    "\n",
    "# Verifico los valores nulos y los tipos de datos\n",
    "print(df_users_items_desanidado.isnull().sum())\n",
    "print(df_users_items_desanidado[['playtime_forever', 'playtime_2weeks']].dtypes)\n",
    "\n",
    "# Lleno los valores nulos con 0\n",
    "df_users_items_desanidado[['playtime_forever', 'playtime_2weeks']] = df_users_items_desanidado[['playtime_forever', 'playtime_2weeks']].fillna(0)\n",
    "\n",
    "# Creo una función para detectar outliers\n",
    "def detect_outliers(df, column):\n",
    "    \"\"\"Detecta los valores atípicos en una columna específica de un DataFrame utilizando el método del rango intercuartil (IQR).\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): El DataFrame en el que se buscarán los valores atípicos.\n",
    "        column (str): El nombre de la columna en la que se buscarán los valores atípicos.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Un DataFrame que contiene solo las filas del DataFrame original que tienen valores atípicos en la columna especificada.\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = df[(df[column] < Q1 - 1.5 * IQR) | (df[column] > Q3 + 1.5 * IQR)]\n",
    "    return outliers\n",
    "\n",
    "# Detecto los outliers para 'playtime_forever' y 'playtime_2weeks'\n",
    "outliers_forever = detect_outliers(df_users_items_desanidado, 'playtime_forever')\n",
    "outliers_2weeks = detect_outliers(df_users_items_desanidado, 'playtime_2weeks')\n",
    "\n",
    "# Muestro un resumen estadístico de la actividad del jugador y los outliers detectados\n",
    "print(df_users_items_desanidado.describe())\n",
    "print(outliers_forever)\n",
    "print(outliers_2weeks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voy a proceder a visualizar en gráficos subplots para comparar los resultados de ambos y manejo de outliers en Tiempos de Juego de Usuarios de Steam y manejo de outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Defino el plot\n",
    "def plot_histogram(ax, data, title, xlabel, ylabel):\n",
    "    ax.hist(data, bins=10, alpha=0.5)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_violinplot(ax, data, labels, ylabel, title):\n",
    "    sns.violinplot(ax=ax, data=data)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Defino los outliers\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    P95 = df[column].quantile(0.95)\n",
    "    df.loc[df[column] > Q3 + 1.5 * IQR, column] = P95\n",
    "\n",
    "# Creo una figura y tres ejes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Creo los histogramas y el gráfico de violín\n",
    "plot_histogram(axs[0], df_users_items_desanidado['playtime_forever'], 'Histograma de Tiempo de Juego Total', 'Tiempo de Juego Total', 'Cantidad de Usuarios')\n",
    "plot_histogram(axs[1], df_users_items_desanidado['playtime_2weeks'], 'Histograma de Tiempo de Juego en las Últimas 2 Semanas', 'Tiempo de Juego en las Últimas 2 Semanas', 'Cantidad de Usuarios')\n",
    "plot_violinplot(axs[2], df_users_items_desanidado[['playtime_forever', 'playtime_2weeks']], ['Tiempo de Juego Total', 'Tiempo de Juego en las Últimas 2 Semanas'], 'Cantidad de Usuarios', 'Gráfico de Violín del Tiempo de Juego')\n",
    "\n",
    "# Muestro los gráficos\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Manejo los outliers para 'playtime_forever' y 'playtime_2weeks'\n",
    "handle_outliers(df_users_items_desanidado, 'playtime_forever')\n",
    "handle_outliers(df_users_items_desanidado, 'playtime_2weeks')\n",
    "\n",
    "# Lleno los valores nulos con 0\n",
    "df_users_items_desanidado['playtime_forever'].fillna(0, inplace=True)\n",
    "df_users_items_desanidado['playtime_2weeks'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:gray\">\n",
    "Los tres gráficos proporcionan una visión detallada de los patrones de juego de los usuarios. El primer gráfico, un histograma del tiempo total de juego, muestra que la mayoría de los usuarios han jugado menos de 50,000 minutos en total, indicando que la mayoría de los usuarios son jugadores ocasionales. Sin embargo, hay algunos usuarios que han jugado mucho más, lo que indica la presencia de jugadores más dedicados.\n",
    "\n",
    "El segundo gráfico es un histograma del tiempo de juego en las últimas 2 semanas. Este gráfico muestra una mayor variabilidad en el tiempo de juego, lo que podría indicar que los patrones de juego de los usuarios cambian con el tiempo, posiblemente debido a factores como el lanzamiento de nuevos juegos, actualizaciones de juegos existentes, o cambios en el tiempo libre de los usuarios.\n",
    "\n",
    "El tercer gráfico es un boxplot que compara la distribución del tiempo total de juego y el tiempo de juego en las últimas 2 semanas. Este gráfico destaca la existencia de outliers, que son usuarios que han jugado significativamente más que otros. Estos outliers podrían ser jugadores extremadamente dedicados o podrían indicar comportamientos de juego anómalos que podrían ser de interés para futuras investigaciones.\n",
    "\n",
    "En conjunto, estos gráficos ofrecen una visión detallada de cómo los usuarios interactúan con los juegos a lo largo del tiempo, lo que podría ser útil para entender mejor los comportamientos de los jugadores y para informar decisiones sobre el diseño de juegos y la orientación de marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procederé a guardar en formato csv cada df que he trabajado ya que no observo datos atípicos ni anomalías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la librería que necesito\n",
    "import os\n",
    "\n",
    "# Diccionario de tus DataFrames y los nombres deseados para los archivos CSV\n",
    "dataframes = {\n",
    "    'df_steam_games': 'steam_games',\n",
    "    'df_user_reviews_desanidado': 'user_reviews',\n",
    "    'df_users_items_desanidado': 'users_items'\n",
    "}\n",
    "\n",
    "# Ruta base donde se guardarán los archivos CSV\n",
    "ruta_base = r'Data'\n",
    "\n",
    "for df_nombre, csv_nombre in dataframes.items():\n",
    "    # Crear la ruta completa del archivo CSV\n",
    "    ruta_archivo_csv = os.path.join(ruta_base, f'{csv_nombre}.csv')   \n",
    "    # Guardar el DataFrame como archivo CSV\n",
    "    globals()[df_nombre].to_csv(ruta_archivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:green\">\n",
    "Ahora lo que voy a realizar es entregar un modelo con sus respectivas etapas de modelado:\n",
    "\n",
    "Evaluación del modelo.\n",
    "\n",
    "Optimización del modelo.\n",
    "\n",
    "Despliegue del modelo como paso final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías necesarias\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cargo los DataFrames\n",
    "df_steam_games = pd.read_csv(r'Data\\steam_games.csv')\n",
    "df_user_reviews_desanidado = pd.read_csv(r'Data\\user_reviews.csv')\n",
    "df_users_items_desanidado = pd.read_csv(r'Data\\users_items.csv')\n",
    "\n",
    "# Tomo una muestra de 100 datos de cada DataFrame\n",
    "df_steam_games_sample = df_steam_games.sample(100)\n",
    "df_user_reviews_desanidado_sample = df_user_reviews_desanidado.sample(100)\n",
    "df_users_items_desanidado_sample = df_users_items_desanidado.sample(100)\n",
    "\n",
    "def PlayTimeGenre(genero: str):\n",
    "    # Filtro df_steam_games_sample por género\n",
    "    games_of_genre = df_steam_games_sample[df_steam_games_sample[genero] == 1]['app_name']\n",
    "    \n",
    "    # Filtro df_users_items_desanidado_sample por juegos del género especificado\n",
    "    playtime_of_genre = df_users_items_desanidado_sample[df_users_items_desanidado_sample['item_name'].isin(games_of_genre)]\n",
    "    \n",
    "    # Agrupo por año y sumar playtime_forever\n",
    "    playtime_by_year = playtime_of_genre.groupby('anio')['playtime_forever'].sum()\n",
    "    \n",
    "    # Encuentro el año con más horas jugadas\n",
    "    year_with_most_playtime = playtime_by_year.idxmax()\n",
    "    \n",
    "    return {\"Año de lanzamiento con más horas jugadas para \" + genero : year_with_most_playtime}\n",
    "\n",
    "def UserForGenre(genero: str):\n",
    "    # Filtro df_steam_games_sample por género\n",
    "    games_of_genre = df_steam_games_sample[df_steam_games_sample[genero] == 1]['app_name']\n",
    "    \n",
    "    # Filtro df_users_items_desanidado_sample por juegos del género especificado\n",
    "    playtime_of_genre = df_users_items_desanidado_sample[df_users_items_desanidado_sample['item_name'].isin(games_of_genre)]\n",
    "    \n",
    "    # Agrupo por usuario y sumar playtime_forever\n",
    "    playtime_by_user = playtime_of_genre.groupby('user_id')['playtime_forever'].sum()\n",
    "    \n",
    "    # Encuentro el usuario con más horas jugadas\n",
    "    user_with_most_playtime = playtime_by_user.idxmax()\n",
    "    \n",
    "    # Agrupo por año y sumar playtime_forever\n",
    "    playtime_by_year = playtime_of_genre.groupby('anio')['playtime_forever'].sum().reset_index()\n",
    "    \n",
    "    # Convierto el DataFrame a una lista de diccionarios\n",
    "    playtime_list = playtime_by_year.to_dict('records')\n",
    "    \n",
    "    return {\"Usuario con más horas jugadas para \" + genero : user_with_most_playtime, \"Horas jugadas\": playtime_list}\n",
    "\n",
    "def UsersRecommend(año: int):\n",
    "    # Filtro df_user_reviews_desanidado_sample por año y recomendación\n",
    "    recommended_games = df_user_reviews_desanidado_sample[(df_user_reviews_desanidado_sample['posted'] == año) & (df_user_reviews_desanidado_sample['recommend'] == True)]\n",
    "    \n",
    "    # Cuento las recomendaciones por juego\n",
    "    recommendations_by_game = recommended_games['item_id'].value_counts()\n",
    "    \n",
    "    # Obtengo el top 3 de juegos más recomendados\n",
    "    top_3_games = recommendations_by_game.nlargest(3).index.tolist()\n",
    "    \n",
    "    return [{\"Puesto 1\" : top_3_games[0]}, {\"Puesto 2\" : top_3_games[1]}, {\"Puesto 3\" : top_3_games[2]}]\n",
    "\n",
    "def UsersNotRecommend(año: int):\n",
    "    # Filtro df_user_reviews_desanidado_sample por año y no recomendación\n",
    "    not_recommended_games = df_user_reviews_desanidado_sample[(df_user_reviews_desanidado_sample['posted'] == año) & (df_user_reviews_desanidado_sample['recommend'] == False)]\n",
    "    \n",
    "    # Cuento las no recomendaciones por juego\n",
    "    not_recommendations_by_game = not_recommended_games['item_id'].value_counts()\n",
    "    \n",
    "    # Obtengo el top 3 de juegos menos recomendados\n",
    "    top_3_games = not_recommendations_by_game.nlargest(3).index.tolist()\n",
    "    \n",
    "    return [{\"Puesto 1\" : top_3_games[0]}, {\"Puesto 2\" : top_3_games[1]}, {\"Puesto 3\" : top_3_games[2]}]\n",
    "\n",
    "def sentiment_analysis(año: int):\n",
    "    # Filtro df_user_reviews_desanidado_sample por año\n",
    "    reviews_of_year = df_user_reviews_desanidado_sample[df_user_reviews_desanidado_sample['posted'] == año]\n",
    "    \n",
    "    # Cuento las reseñas para análisis de sentimiento\n",
    "    sentiment_counts = reviews_of_year['sentiment_analysis'].value_counts().to_dict()\n",
    "    \n",
    "    return sentiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_steam_games.columns)\n",
    "print(df_user_reviews_desanidado.columns)\n",
    "print(df_users_items_desanidado.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
